深层神经网络是实现多层非线性变换最常用的一种方法。深度学习有两个非常重要的特性——多层和非线性。
1.线性模型的局限性：
	线性模型的最大特点是任意的线性模型的组合仍然是线性模型，所以只通过线性变换，任意层的全连接神经网络和单层神经网络模型的表达能力没有任何区别
  （即便是多层神经网络，实质上就是单层的神经网络），而且他们都是线性模型。然后线性模型能够解决的问题是有限的。所以深度学习是用来解决“复杂”问
  题的，所谓“复杂”，就是无法通过直线（或者高维空间的平面）划分的，而且现实生活中绝大部分的问题都是无法线性分割的，所以我们需要引入非线性元素。
2.非线性激活函数的使用：
	我们将每一个神经元（也就是神经网络的一个节点）的输出通过一个非线性函数，那么整个神经网络的模型也就不再是线性的了。这个非线性函数就是激活函
  数。
	非线性激活函数引入的两个改变：第一就是偏置项；第二就是非线性激活函数
3.多层神经网络的作用：
	来源于拟合异或函数，深层神经网络实际上有组合特征提取的功能，能从输入特征中抽取更高维的特征。这个特性对于解决不易提取向量的问题（比如图片识
  别、语音识别等）有很大的帮助。所以通过多层神经网络我们能提取到更加抽象的复杂的特征向量用于分类。
4.关于低维特征和高维特征的理解
	根据深度学习关于人的视觉分层的理论，人的视觉对目标的辨识是分层的，低层会提取一些边缘特征（低维特征），然后高一些层次进行形状或目标的认知，
  更高层的会分析一些运动和行为。也就是说高层的特征（高维特征）是低层特征（低维特征）的组合，从低层到高层的特征表示越来越抽象，越来越能表现语义
  或者意图。而抽象层面越高，存在的可能猜测就越少，就越利于分类。而深度学习就是通过这种分层的自动特征提取来达到目标分类，先构建一些基本的特征层，
  然后用这些基础特征去构建更高层的抽象，更精准的分类特征。
	例如在CNN中，我们的卷积层就是特征提取层，池化层就是降维层。
	NOTE：一方面多层神经网络能从输入特征中抽取更高维的特征，这里的高维是抽象，复杂的意思；另一方面，在卷积神经网络中我们又设计了池化层来降低特征
  维度，也就是从高维特征集合中选出低维特征集合，这里的高维指的是繁多的，冗余的，具有强相关度的特征。
5.
